
OpenEssayist: An Automated Feedback System that Supports University Students as they Write Summative Essays


Abstract

OpenEssayist is an automated, interactive feedback system designed to provide an acceptable level of support for
students as they write essays for summative assessment. There are two main components to the system: (1) a
linguistic analysis engine and (2) a web application that generates feedback for students The main pedagogical
challenge in the e-assessment of free text is how to provide meaningful “advice for action” in order to support
students writing their summative assessments. We have built a first working version of the system in which we use
unsupervised graph-based ranking algorithms (following Mihalcea & Tarau, 2005) to automatically extract key
words, phrases and sentences from student essays. We have developed several external representations of these
summarisation techniques. For examples, key words and key phrases can be viewed in a word cloud or in a
dispersion graph, and they can be explored and organised into groups. Holistic approaches have also been tested
using ‘mash ups’ where key words and key sentences are highlighted in context in the essay itself, helping students
to investigate the distribution of key words and its potential implications for the clarity of the narrative. This paper
will report the findings from our pilot studies of the interactive models associated with the summarisation
techniques.

Keywords

Automated feedback; essay writing; summary; external representations

Introduction

OpenEssayist is a web application that has been designed to assist students while writing their essays
for summative assessment. 'Summative assessment' is defined as “an assessment that is administered at
the end of a learning sequence. It is designed to form a judgement about learning that is often reported
in terms of grades or scores and is underpinned by a set of quality assurance processes” (Whitelock,
2011, p. 341). Students who are new to writing essays in higher education and who have returned after
a break of many years to undertake a Masters Level qualification often experience difficulty in writing
their first summative essay and ‘drop out’ of the course (Simpson, 2003). Therefore the goal of this
application is to provide students with feedback on their draft essays before they submit them for
summative assessment.

OpenEssayist consists of two major components (1) a linguistic engine and (2) a web application that
generates feedback for students (Van Labeke et al, 2013). Understanding how to provide appropriate
feedback to students to enable them to move forward with their essay writing is the focus of this paper
since providing meaningful feedback or “advice for action” (Whitelock, 2011) needed to be user tested
before the system went live in September 2013. A round of supervised, observed user testing was
therefore organised, having six participants.

This paper reports on how well the participants understood a range of external representations
generated by OpenEssayist in order to assist with essay improvements before submission. The findings
have informed the selection of the final representations that will be used for students following a
postgraduate module entitled “Accessible online learning: Supporting disabled students". This
postgraduate module runs in September 2013 for about 20 weeks and contributes to a Master of Arts
(MA) in Online and Distance Education. All modules, materials and support are delivered online.
Students on this module, as is the case for most of the students at the Open University (OU), are parttime,
mature students, many of whom have not been in formal education for a long period of time.
The user testing was designed to understand how to provide meaningful representations of the analysis
of draft essays by exploring text analysis outputs and visual analysis outputs

OpenEssayist: The Linguistic Engine


(http://oro.open.ac.uk/41844/)

---
